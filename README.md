# EfficientDNN-PaperList
Paper list for deep neural network compression and acceleration
## Low-Rank 
* Low-Rank Expansions
	* Jaderberg et al., "Speeding up Convolutional Neural Networks with Low Rank Expansions". BMVC2014
* SVD
	 * Denton et al, "Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation". NIPS2014
	 * Zhang et al., “Accelerating Very Deep Convolutional Networks for Classification and Detection”. TPAMI 2016.
* CP Decomposition
	* Lebedev et al., “Speeding-up Convolutional Neural Networks using Fine-tuned CP-Decomposition”. ICLR 2015
* Tucker Decomposition
	 * Kim et al., “Compression of Deep Convolutional Neural Networks for Fast and Low Power  Mobile Applications”. ICLR 2016
* Block Term Decomposition
    * Wang et al., “Accelerating Convolutional Neural Networks for Mobile Applications”. MM 2016.
    * Ye et al., “Learning Compact Recurrent Neural Networks with Block-Term Tensor Decomposition ”. CVPR2018.
* Tensor Train Decomposition
    * Novikov et al., “Tensorizing Neural Networks”. NIPS 2016.
* Tensor Ring (TR) Factorization
    * Wang et al., “Wide Compression: Tensor Ring Nets”. CVPR2018

